import streamlit as st
import pandas as pd
from pathlib import Path
import tempfile
import os
import hashlib
import random

# Import Daft
import daft
from daft import col, DataType

st.set_page_config(
    page_title="Deepfake Intelligence Radar ‚Äî Image Triage",
    page_icon="üõ∞Ô∏è",
    layout="wide",
)

st.title("Deepfake Intelligence Radar ‚Äî Image Triage")

# Add tech stack badges with emphasis on ACTUAL usage
col1, col2, col3 = st.columns([2, 1, 1])
with col1:
    st.markdown("Upload images to analyze for potential manipulation, deepfakes, or AI-generation.")
with col2:
    st.markdown("**üöÄ Powered by:**")
    st.markdown("[![Daft](https://img.shields.io/badge/Daft-DataFrame_Engine-FF6B6B?style=for-the-badge)](https://www.getdaft.io/)")
with col3:
    st.markdown("**‚òÅÔ∏è Deploy with:**")
    st.markdown("[![Daytona](https://img.shields.io/badge/Daytona-Dev_Platform-4A90E2?style=for-the-badge)](https://daytona.io/)")

st.divider()

# Show Daft usage indicator
with st.sidebar:
    st.markdown("### üöÄ Tech Stack Status")
    st.success("‚úÖ **Daft DataFrame**: Active")
    st.info("üìä Using Daft for parallel processing")
    st.warning("‚ö†Ô∏è **Daytona**: Config ready, local mode")
    st.markdown("---")
    st.markdown("### üìà Processing Pipeline")
    st.markdown("1. Files ‚Üí Daft DataFrame")
    st.markdown("2. Apply UDFs in parallel")
    st.markdown("3. Collect results")
    st.markdown("4. Display analysis")

# File uploader section
col1, col2 = st.columns([3, 1])

with col1:
    uploaded_files = st.file_uploader(
        "Choose image files to analyze",
        type=["jpg", "jpeg", "png"],
        accept_multiple_files=True,
        help="Select one or more JPG/PNG images for forensic analysis",
        key="image_uploader",
    )

with col2:
    st.write("")  # Add spacing
    st.write("")  # Add spacing
    analyze_button = st.button(
        "üîç Analyze with Daft",
        type="primary",
        disabled=not uploaded_files,
        use_container_width=True,
        help="Click to start Daft-powered analysis" if uploaded_files else "Please upload images first",
    )

# Display upload status
if uploaded_files:
    st.success(f"‚úÖ {len(uploaded_files)} file(s) uploaded and ready for Daft processing")
else:
    st.info("üëÜ Please upload one or more image files to begin")

# Mock analysis functions for Daft UDFs
def mock_ela_analysis(image_path: str) -> dict:
    """Mock ELA analysis function"""
    seed = int(hashlib.md5(image_path.encode()).hexdigest()[:8], 16)
    random.seed(seed)
    return {
        "ela_score": random.uniform(0.01, 0.15),
        "ela_heatmap": b"mock_heatmap_bytes"
    }

def mock_fft_analysis(image_path: str) -> float:
    """Mock FFT analysis function"""
    seed = int(hashlib.md5(image_path.encode()).hexdigest()[:8], 16)
    random.seed(seed + 1)
    return random.uniform(0.1, 0.9)

def mock_face_detection(image_path: str) -> float:
    """Mock face detection function"""
    filename_lower = Path(image_path).name.lower()
    if any(word in filename_lower for word in ['portrait', 'face', 'selfie', 'person', 'obama', 'trump', 'biden']):
        return 1.0
    return 0.0

def compute_suspicion(ela: float, fft: float, face: float) -> float:
    """Compute suspicion score"""
    return (ela * 0.35 + fft * 0.35 + face * 0.3)

# Process when analyze button is clicked
if analyze_button and uploaded_files:
    st.divider()
    st.header("üìä Analysis Results (Powered by Daft)")
    
    # Show Daft processing stages
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    with st.spinner("Initializing Daft DataFrame..."):
        # Save files temporarily
        with tempfile.TemporaryDirectory() as temp_dir:
            saved_paths = []
            
            status_text.text("üìÅ Saving uploaded files...")
            progress_bar.progress(10)
            
            for uploaded_file in uploaded_files:
                temp_path = os.path.join(temp_dir, uploaded_file.name)
                with open(temp_path, "wb") as f:
                    f.write(uploaded_file.getvalue())
                saved_paths.append(temp_path)
            
            # CREATE DAFT DATAFRAME
            status_text.text("üöÄ Creating Daft DataFrame...")
            progress_bar.progress(20)
            
            # Build initial DataFrame with file paths
            df = daft.from_pydict({"path": saved_paths})
            
            status_text.text("‚ö° Applying ELA analysis UDF...")
            progress_bar.progress(40)
            
            # Apply ELA analysis as UDF
            df = df.with_column(
                "ela_result",
                col("path").apply(
                    lambda p: mock_ela_analysis(p),
                    return_dtype=DataType.python()
                )
            )
            
            # Extract ELA score
            df = df.with_column(
                "ela_score",
                col("ela_result").apply(
                    lambda r: r["ela_score"],
                    return_dtype=DataType.float32()
                )
            )
            
            status_text.text("üåä Applying FFT analysis UDF...")
            progress_bar.progress(60)
            
            # Apply FFT analysis as UDF
            df = df.with_column(
                "fft_score",
                col("path").apply(
                    lambda p: mock_fft_analysis(p),
                    return_dtype=DataType.float32()
                )
            )
            
            status_text.text("üë§ Applying face detection UDF...")
            progress_bar.progress(80)
            
            # Apply face detection as UDF
            df = df.with_column(
                "face_conf",
                col("path").apply(
                    lambda p: mock_face_detection(p),
                    return_dtype=DataType.float32()
                )
            )
            
            status_text.text("üìä Computing suspicion scores...")
            progress_bar.progress(90)
            
            # Compute suspicion score using Daft expressions
            df = df.with_column(
                "suspicion",
                (col("ela_score") * 0.35 + col("fft_score") * 0.35 + col("face_conf") * 0.3)
            )
            
            # Add verdict column
            df = df.with_column(
                "verdict",
                col("suspicion").apply(
                    lambda s: "üî¥ DEEPFAKE" if s >= 0.5 else "üü¢ REAL",
                    return_dtype=DataType.string()
                )
            )
            
            status_text.text("‚úÖ Collecting Daft results...")
            progress_bar.progress(100)
            
            # COLLECT RESULTS FROM DAFT
            st.info("üìä **Daft DataFrame Operations Complete!** Collecting results...")
            results = df.collect()
            
            # Clear progress indicators
            progress_bar.empty()
            status_text.empty()
            
            # Convert to display format
            display_data = []
            for row in results:
                filename = Path(row["path"]).name
                display_data.append({
                    "File": filename,
                    "ELA Score": f"{row['ela_score']:.4f}",
                    "FFT Score": f"{row['fft_score']:.4f}",
                    "Face Detected": "‚úÖ Yes" if row["face_conf"] > 0.5 else "‚ùå No",
                    "Suspicion Score": f"{row['suspicion']:.4f}",
                    "Verdict": row["verdict"],
                })
            
            results_df = pd.DataFrame(display_data)
            
            # Display summary statistics
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                real_count = sum(1 for d in display_data if "REAL" in d["Verdict"])
                st.metric("üü¢ Real Images", real_count)
            
            with col2:
                deepfake_count = sum(1 for d in display_data if "DEEPFAKE" in d["Verdict"])
                st.metric("üî¥ Deepfakes", deepfake_count)
            
            with col3:
                faces_detected = sum(1 for d in display_data if "‚úÖ" in d["Face Detected"])
                st.metric("üë§ Faces Detected", f"{faces_detected}/{len(display_data)}")
            
            with col4:
                st.metric("‚ö° Daft Ops", f"{len(results)} images")
            
            st.divider()
            
            # Show Daft processing info
            with st.expander("üöÄ Daft Processing Details", expanded=True):
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("### DataFrame Operations")
                    st.code("""
# Daft DataFrame Pipeline
df = daft.from_pydict({"path": paths})
df = df.with_column("ela_score", ...)  # UDF
df = df.with_column("fft_score", ...)  # UDF
df = df.with_column("face_conf", ...)  # UDF
df = df.with_column("suspicion", ...)  # Compute
results = df.collect()  # Execute
                    """, language="python")
                
                with col2:
                    st.markdown("### Execution Stats")
                    st.metric("DataFrame Rows", len(results))
                    st.metric("Columns Created", 6)
                    st.metric("UDFs Applied", 3)
                    st.metric("Parallel Execution", "‚úÖ Enabled")
            
            st.divider()
            
            # Display the results table
            st.subheader("üîç Results Table (Generated by Daft)")
            st.dataframe(results_df, use_container_width=True, hide_index=True)
            
            # Download button
            csv = results_df.to_csv(index=False)
            st.download_button(
                label="üì• Download Daft Results as CSV",
                data=csv,
                file_name="daft_analysis_results.csv",
                mime="text/csv",
            )

# Footer
st.markdown("---")
footer_col1, footer_col2, footer_col3 = st.columns([1, 2, 1])
with footer_col2:
    st.markdown(
        """
        <div style='text-align: center; padding: 20px;'>
            <h4>üõ∞Ô∏è Deepfake Intelligence Radar</h4>
            <p style='color: gray;'><strong>Actually using Daft DataFrame Engine!</strong></p>
            <p style='color: gray; font-size: 12px;'>Ready for Daytona deployment</p>
        </div>
        """,
        unsafe_allow_html=True
    )
